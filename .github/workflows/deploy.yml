name: Deploy Fullstack App to AWS (CloudFormation, EC2, ECR, S3, CloudFront)

on:
  push:
    branches: [main]

jobs:
  deploy-infrastructure:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      - name: Delete failed CloudFormation stack (if in ROLLBACK or CREATE_FAILED state)
        run: |
          STATUS=$(aws cloudformation describe-stacks --stack-name sdn-stack --region ${{ secrets.AWS_REGION }} --query "Stacks[0].StackStatus" --output text || echo "NOT_FOUND")
          if [[ "$STATUS" == "ROLLBACK_IN_PROGRESS" || "$STATUS" == "ROLLBACK_COMPLETE" || "$STATUS" == "CREATE_FAILED" ]]; then
            echo "Deleting failed stack sdn-stack..."
            aws cloudformation delete-stack --stack-name sdn-stack --region ${{ secrets.AWS_REGION }}
            aws cloudformation wait stack-delete-complete --stack-name sdn-stack --region ${{ secrets.AWS_REGION }}
          else
            echo "No failed stack to delete. Current status: $STATUS"
          fi
      - name: Deploy CloudFormation stack
        run: |
          aws cloudformation deploy \
            --template-file infrastructure.yml \
            --stack-name sdn-stack \
            --capabilities CAPABILITY_NAMED_IAM \
            --region ${{ secrets.AWS_REGION }}
      - name: Show CloudFormation stack failures
        if: failure()
        run: |
          echo "Showing failed stack events for sdn-stack..."
          aws cloudformation describe-stack-events --stack-name sdn-stack --region ${{ secrets.AWS_REGION }} \
            --query "StackEvents[?ResourceStatus=='CREATE_FAILED'].[LogicalResourceId,ResourceStatusReason]" \
            --output table
  build-backend:
    runs-on: ubuntu-latest
    needs: [deploy-infrastructure]
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build Docker image
        run: |
          docker build -t ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com/sdn-backend-${{ secrets.AWS_ACCOUNT_ID }}-${{ secrets.AWS_REGION }}:latest ./backend

      - name: Remove all ECR images
        run: |
          IMAGE_IDS=$(aws ecr list-images \
            --repository-name sdn-backend-${{ secrets.AWS_ACCOUNT_ID }}-${{ secrets.AWS_REGION }} \
            --region ${{ secrets.AWS_REGION }} \
            --query 'imageIds[*]' \
            --output json)
          if [ "$IMAGE_IDS" != "[]" ]; then
            aws ecr batch-delete-image \
              --repository-name sdn-backend-${{ secrets.AWS_ACCOUNT_ID }}-${{ secrets.AWS_REGION }} \
              --region ${{ secrets.AWS_REGION }} \
              --image-ids "$IMAGE_IDS"
          else
            echo "No images to delete."
          fi

      - name: Push Docker image to ECR
        run: |
          docker push ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com/sdn-backend-${{ secrets.AWS_ACCOUNT_ID }}-${{ secrets.AWS_REGION }}:latest

  deploy-backend:
    runs-on: ubuntu-latest
    needs: [build-backend]
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Write SSH key to file
        run: |
          echo "${{ secrets.EC2_SSH_KEY }}" > /tmp/ec2_key.pem
          chmod 600 /tmp/ec2_key.pem

      - name: Get EC2 Public IP
        id: get_ec2_ip
        run: |
          PUBLIC_IP=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=sdn-ec2-instance" "Name=instance-state-name,Values=running" \
            --region ${{ secrets.AWS_REGION }} \
            --query "Reservations[0].Instances[0].PublicIpAddress" \
            --output text)
          echo "EC2_HOST=$PUBLIC_IP" >> $GITHUB_ENV

      - name: Copy docker-compose.yml and nginx.conf to EC2
        run: |
          scp -i /tmp/ec2_key.pem -o StrictHostKeyChecking=no backend/docker-compose.yml backend/nginx.conf ec2-user@${{ env.EC2_HOST }}:~/

      - name: Deploy to EC2
        uses: appleboy/ssh-action@master
        with:
          host: ${{ env.EC2_HOST }}
          username: ec2-user
          key: ${{ secrets.EC2_SSH_KEY }}
          timeout: 30m
          envs: AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,AWS_REGION,BACKEND_ENV
          script: |
            export AWS_ACCESS_KEY_ID="${{ secrets.AWS_ACCESS_KEY_ID }}"
            export AWS_SECRET_ACCESS_KEY="${{ secrets.AWS_SECRET_ACCESS_KEY }}"
            export AWS_REGION="${{ secrets.AWS_REGION }}"
            set -exuo pipefail
            sudo yum install -y docker
            sudo systemctl start docker
            sudo systemctl enable docker
            sudo usermod -aG docker ec2-user

            # Install docker-compose
            sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
            sudo chmod +x /usr/local/bin/docker-compose

            # Login to ECR
            aws ecr get-login-password --region ${{ secrets.AWS_REGION }} | sudo docker login --username AWS --password-stdin ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com

            cd ~/

            # Set up environment variables
            echo "${{ secrets.BACKEND_ENV }}" > .env
            echo "BACKEND_IMAGE=${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com/sdn-backend-${{ secrets.AWS_ACCOUNT_ID }}-${{ secrets.AWS_REGION }}:latest" >> .env

            # Clean up unused Docker resources
            sudo docker system prune -af

            # Pull latest image and start containers
            sudo docker-compose down || true
            sudo docker-compose pull
            sudo docker-compose up -d

            # Health check
            curl -v http://localhost:80 || true

  build-frontend-next:
    runs-on: ubuntu-latest
    needs: [deploy-infrastructure]
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build Docker image
        run: |
          docker build -t ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com/sdn-frontend-next-${{ secrets.AWS_ACCOUNT_ID }}-${{ secrets.AWS_REGION }}:latest ./frontend-next

      - name: Remove all ECR images
        run: |
          IMAGE_IDS=$(aws ecr list-images \
            --repository-name sdn-frontend-next-${{ secrets.AWS_ACCOUNT_ID }}-${{ secrets.AWS_REGION }} \
            --region ${{ secrets.AWS_REGION }} \
            --query 'imageIds[*]' \
            --output json)
          if [ "$IMAGE_IDS" != "[]" ]; then
            aws ecr batch-delete-image \
              --repository-name sdn-frontend-next-${{ secrets.AWS_ACCOUNT_ID }}-${{ secrets.AWS_REGION }} \
              --region ${{ secrets.AWS_REGION }} \
              --image-ids "$IMAGE_IDS"
          else
            echo "No images to delete."
          fi

      - name: Push Docker image to ECR
        run: |
          docker push ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com/sdn-frontend-next-${{ secrets.AWS_ACCOUNT_ID }}-${{ secrets.AWS_REGION }}:latest

  deploy-frontend-next:
    runs-on: ubuntu-latest
    needs: [build-frontend-next]
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Write SSH key to file
        run: |
          echo "${{ secrets.EC2_SSH_KEY }}" > /tmp/ec2_key.pem
          chmod 600 /tmp/ec2_key.pem

      - name: Get EC2 Public IP
        id: get_ec2_ip
        run: |
          PUBLIC_IP=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=frontend-next-ec2-instance" "Name=instance-state-name,Values=running" \
            --region ${{ secrets.AWS_REGION }} \
            --query "Reservations[0].Instances[0].PublicIpAddress" \
            --output text)
          echo "EC2_HOST=$PUBLIC_IP" >> $GITHUB_ENV

      - name: Copy docker-compose.yml to EC2
        run: |
          scp -i /tmp/ec2_key.pem -o StrictHostKeyChecking=no frontend-next/docker-compose.yml frontend-next/nginx.conf ec2-user@${{ env.EC2_HOST }}:~/

      - name: Copy .env to EC2
        run: |
          echo "${{ secrets.FRONTEND_NEXT_ENV }}" > .env
          echo "FRONTEND_NEXT_IMAGE=${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com/sdn-frontend-next-${{ secrets.AWS_ACCOUNT_ID }}-${{ secrets.AWS_REGION }}:latest" >> .env

      - name: Deploy to EC2
        uses: appleboy/ssh-action@master
        with:
          host: ${{ env.EC2_HOST }}
          username: ec2-user
          key: ${{ secrets.EC2_SSH_KEY }}
          timeout: 30m
          envs: AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,AWS_REGION,FRONTEND_NEXT_ENV
          script: |
            export AWS_ACCESS_KEY_ID="${{ secrets.AWS_ACCESS_KEY_ID }}"
            export AWS_SECRET_ACCESS_KEY="${{ secrets.AWS_SECRET_ACCESS_KEY }}"
            export AWS_REGION="${{ secrets.AWS_REGION }}"
            set -exuo pipefail
            sudo yum install -y docker
            sudo systemctl start docker
            sudo systemctl enable docker
            sudo usermod -aG docker ec2-user

            # Install docker-compose
            sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
            sudo chmod +x /usr/local/bin/docker-compose

            # Login to ECR
            aws ecr get-login-password --region ${{ secrets.AWS_REGION }} | sudo docker login --username AWS --password-stdin ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com

            cd ~/

            # Clean up unused Docker resources
            sudo docker system prune -af

            # Pull latest image and start containers
            sudo docker-compose down || true
            sudo docker-compose pull
            sudo docker-compose up -d

            # Health check
            curl -v http://localhost:4000 || true

  build-and-deploy-frontend-spa:
    runs-on: ubuntu-latest
    needs: [deploy-infrastructure]
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 22

      - name: Install dependencies and build
        working-directory: ./frontend-spa
        env:
          VITE_API_URL: ${{ secrets.VITE_API_URL }}
        run: |
          npm install
          npm run build

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Deploy to S3
        run: |
          aws s3 sync ./frontend-spa/dist s3://sdn-frontend-spa-${{ secrets.AWS_ACCOUNT_ID }}-${{ secrets.AWS_REGION }} --delete

      - name: Log S3 bucket Website endpoint URL
        run: |
          echo "( CloudFront URL with domain name ) S3 Website endpoint URL: https://secret-domain.net/"
          aws s3 ls s3://sdn-frontend-spa-${{ secrets.AWS_ACCOUNT_ID }}-${{ secrets.AWS_REGION }}

  invalidate-cloudfront:
    runs-on: ubuntu-latest
    needs: [deploy-backend, deploy-frontend-next, build-and-deploy-frontend-spa]
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Get CloudFront Distribution ID from CloudFormation
        id: get_cf_id
        run: |
          CF_ID=$(aws cloudformation describe-stacks \
            --stack-name sdn-stack \
            --region ${{ secrets.AWS_REGION }} \
            --query "Stacks[0].Outputs[?OutputKey=='CloudFrontDistributionId'].OutputValue" \
            --output text)
          echo "CLOUDFRONT_DISTRIBUTION_ID=$CF_ID" >> $GITHUB_ENV

      - name: Invalidate CloudFront cache
        run: |
          aws cloudfront create-invalidation --distribution-id $CLOUDFRONT_DISTRIBUTION_ID --paths "/*"
